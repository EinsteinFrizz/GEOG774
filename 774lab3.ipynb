{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Lab 3 - Programming with Jupyter Notebooks and ArcGIS Portal</h1>\n",
    "<p>Make sure to save this notebook in a new directory on your VM for this lab (e.g. <code>C:\\data\\lab3</code>). We will be creating new files during this assignment which will be created in the same directory the notebook is saved.</p>\n",
    "<h2>Part 2: Getting Business Data from Yelp</h2>\n",
    "<p>Let's start by adding in some extra Python features so that we can acess Yelp. We do this by importing some pre-written libraries of code at the top of our Python program. Run the cell below to load the libraries into the kernel.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is used to make sure the modules we need are loaded into the kernel\n",
    "import requests # handles the internet data requests\n",
    "import psycopg2 #makes connecting to a PostGIS database easy\n",
    "import json #makes working with JSON data easy as pie\n",
    "import csv \n",
    "import ast\n",
    "import time\n",
    "from pprint import pprint as pp\n",
    "\n",
    "import re\n",
    "from gensim import corpora, models\n",
    "import logging #get some logging going to make it easier to debug\n",
    "logging.basicConfig(filename='lab3.log',level=logging.DEBUG, filemode='w')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next, we are going to create a <code>variable.</code> Variables store information in our program so that we can access them later on without having to type the data in every time, or in case the value of the variable is set by a computer function. We are going to create a variable named <code>endpoint</code> that stores the web URI for the Yelp dataset, and another called <code>headers.</code></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://api.yelp.com/v3/businesses/search'\n",
    "headers = {'Authorization':'Bearer YOUR API KEY HERE'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to set the parameters of a <code>query.</code> A query is a programmers way of asking a website for specific data. In this case we are going to ask for data from the Yelp businesses endpoint (the variable endpoint!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'latitude':'-36.872' , 'longitude':'174.74' ,'limit':'50' ,'radius':'500'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we are asking for 50 businesses within a 500-meter buffer of the latitude-longitude pair for Kingsland. This is the max number we are allowed to ask for. This means that if we get a full 50, there are actually more in that area then Yelp allows us to have. In order to get all the data, you would need to decrease the radius and run the query in more than one location.<br><br>\n",
    "Next, we will actually ask for the results by creating a variable called <code>payload</code>, and then we are using the library we imported at the top called <code>requests.</code> Inside that code library there is a method, like <code>print</code> that we used for “hello world” when we first set up Jupyter, except instead of printing to the screen, it sends out the request parameters to Yelp, and gets back what Yelp has sent us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = requests.get(endpoint,params=params,headers=headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you ran the above cell it won't do anything as far as we can tell. That's because we asked for some data, and then didnt do anything with it, until now. Hit run on the cell below. This will produce lots of output that is a bit hard to read, but through it will you will see the JSON data you collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving the Output of our Program</h3>\n",
    "<p>The data that Yelp sends us back is in a format called JSON, which stands for JavaScript Object Notation. What we want however is to write out the data in a format that we can import to a GIS like ArcGIS or QGIS.<br>\n",
    "First, we will save this JSON data to a file that you can open later if you want. We are going to use the <code>dump</code> method. To use the dump command, we create a command that needs two lines.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yelp.json','w') as f:\n",
    "    json.dump(payload,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that there is a ‘tab’ indent on the second line. It’s really important! This is how Python knows that the second line is related to the first line. Also note how the second line is a sub-clause to the first line, this means that it evaluates based on the line above. Later in this program we are going to write a command that allows us to make a <code>loop</code> which will also use sub-clause lines that define what happens each time through the loop.</p><hr>\n",
    "<p>After running this cell, the program will write out our data to a new file called <code>yelp.json</code> with 50 businesses worth of data! This will appear in the same folder that you saved this notebook to.</p><br>\n",
    "The last thing to do before we move on is to learn to use <code>comments.</code> You’ve probably seen comments in this class when mucking around with html/JavaScript, but it’s time we really used them properly. \n",
    "Comments are a way of telling the compiler (the thing that runs the code) to skip a line (or lines) that you are currently on. Different languages use different characters for comments. In HTML it is &lt;!-- --&gt; and in JavaScript it is //. Python uses #.\n",
    "There are two things you might want to use comments for in our code. \n",
    "<ol><li>To remove code you don’t want to run, but you don’t want to delete either. This can be useful when hunting for bugs in your code</li>\n",
    "    <li>To provide extra clarity to the code that you are writing, i.e. to comment on it.</li></ol>\n",
    "\n",
    "<p>You can add a comment to a whole line, or to just after the bit of code you are writing. The latter is called an inline comment.<br>\n",
    "Go through the rest of the cells in our short program and add meaningful comments so that it can be read by somebody other than you.<b> Later in this assignment when you create your final screenshots and code, I will expect good use of comments or marks will be taken away.</b></p>\n",
    "\n",
    "<h3>Saving the data to CSV</h3>\n",
    "<p>In the last step we saved our data, but this data is in a format that isn’t super useful just yet. We need to translate it into a format that QGIS or ArcMap (common GIS software) know how to use.<br><br>\n",
    "If we look at the JSON file we can see that there is a bunch of information at the top describing the result of our data, and then there is a <code>[</code> character and then the data is really useful after that. What we need to do is get Python to output just the data for each restaurant and the relevant information. </p>\n",
    "<h3>For Loops</h3>\n",
    "<p>To accomplish this, we use a <code>loop</code>.</b> There are multiple types of loops, but in this case, we will use a <code>for loop</code> type. This goes through each of the businesses we are interested in and performs commands. Before we write our CSV code, let’s take a quick look at how a for loop works.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This creates a new variable called <code>I</code> and sets it's value to be an array with five items; <code>1,2,3,4 & 5.</code><br>\n",
    "What we want to do next is create a loop to iterate over that list by adding some new lines of code</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = [1,2,3,4,5]\n",
    "for i in I:\n",
    "    print(\"line: \"+str(i)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Great work! What has happened here is that the for loop looked at the array <code>l</code> and noted that there were five items in it. For each of these items, the loop printed them out with the <code>print</code> statement. You’ll notice that I used three helping functions here.</p>\n",
    "<ul><li>The <code>+ command.</code> When we have a line of text, we can add more text using the <code>+ command</code>, like <code>“Hello”+”World”</code> would result in <code>“HelloWorld”</code></li>\n",
    "<li>I also made use of the <code>str() command.</code> What <code>str()</code> does is convert the numbers in the array to strings (characters) to that we can join them using the <code>+ command.</code></li>\n",
    "<li>Lastly, I used <code>“\\n”</code> the slash here indicates that there is a special type of character coming in that does a command. In this case <code>\"\\n\"</code> means new line. If we used <code>\"\\t\"</code> it would format a tab. Importantly, if you wanted to have text that used a <code>\\n</code> (emoji’s are the worst), then you use a double slash, <code>\"\\\\n\".</code> This comes up a lot when typing file locations.</li></ul>\n",
    "\n",
    "<h3>CSV loop</h3>\n",
    "<p>Now, let's move in to that CSV (Comma Separated Values) data. CSV is a common data type that Excel and GIS software are happy to work with. This is tabular information that distributes each of the values in a single line, for example:<br>\n",
    "<code>name,location.rating.expense\n",
    "mike's,kingsland,5,$$$</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_good = [['name','rating','url','price','lat','long','category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This code sets up up a new array for holding the JSON data. The first line of a CSV file usually holds the column names, and this is the data we are interested in so it makes sense. Each row of the data will be a new array inside our payload array, in effect making it an <i>array of arrays.</i> An array is simply a list, so this is <i>a list of lists.</i><br>\n",
    "\n",
    "So, now we make our for loop. In the loop we are going to iterate through each of the businesses in the JSON data, and then capture each of the data items we want into a new variable for each. Normally when we code we do this kind of operation all in one ugly line of code, but for the sake of making it understandable, I’m going to write each out here</p><br>\n",
    "<b>Look over the following code and add comments that explain what everything does<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for business in payload['businesses']:\n",
    "    lat = str(business['coordinates']['latitude'])\n",
    "    lon = str(business['coordinates']['longitude'])\n",
    "    name = str(business['name'])\n",
    "    url = str(business['url'])\n",
    "    price = business['price'] if 'price' in business else \"null\"\n",
    "    rating = str(business['rating'])\n",
    "    category = str(business['categories'][0]['title'])\n",
    "    \n",
    "    l = [name,rating,url,price,lat,lon,category]\n",
    "    \n",
    "    #in case of errors this is a debug line\n",
    "    #print(l)\n",
    "    \n",
    "    payload_good.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so what happened here? \n",
    "<ol><li>First, I created the for loop, and I told it to go through each business in the json file, which has a <code>key</code> (or property) called <code>‘businesses’.</code></li>\n",
    "<li>Then, for each business, I pulled out the keys that we want using their key name; for example <code>business[‘url’].</code></li>\n",
    "<li>For latitude and longitude, I had to do a little extra work, because the lat/long pairs are in JSON format, so I used the sub-key by adding it to the end of <code>business[‘coordinates’]</code> so <code>business[‘coordinates’][‘latitude’]</code></li>\n",
    "<li>For the price, it turned out that not all businesses have a price rating! So, to combat this I added a simple check on if there was a <code>‘price’</code> key in the business data. I used another new command, called an <code>if statement.</code> Basically the way you can read the line is: set the value of <code>price</code> to <code>business[‘price’]</code> if a price exists, otherwise, <code>price='null'</code></li>\n",
    "<ul><li>Important here is that as you get more data, other counts  might not be included. While I didn’t need this now, you might want to add more ‘if’ statements to your array in order to account for potential issues.</li></ul>\n",
    "<li>I create a new array <code>l</code>, with its values set to be the items I just pulled out of the business data.</li>\n",
    "<li>Then, I print out the data so I can see what happening, because an earlier version of the program had errors (the price issue) and I wanted to see where it went wrong.</li>\n",
    "<li>Finally, I add the array <code>l</code> to the list <code>payload_good.</code></li></ol>\n",
    "\n",
    "<p>In this format, the array <code>payload_good</code> grows, with each item in the array equalling a new row in our csv file. \n",
    "You can run this code if you want to see it work, but remember that the code that wrote the JSON is above. This will overwrite the existing data file, but that is not a big deal at this point, really.</p>\n",
    "\n",
    "<p>Lastly we are going to write our <code>payload_good</code> data to a CSV file so that we can use it with QGIS, ArcGIS and Excel:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yelp.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerows(payload_good)\n",
    "    \n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFFF00\"><b>Note: The last 3 cells have been separated so that we could work through it step by stem. Combine them into one cell when you begin playing around later to save having to run each one separately.</b>\n",
    "<p><b>Head back to the main instructions document</b> to check an example of the completed code, and for instructions on how to open and view your data in QGIS. <b>You will need to submit a map of your requested Yelp data in your assignment.</b></p>\n",
    "<h2>Part 3: Getting Restaurant Reviews and Storing in PostGIS</h2>\n",
    "<h3>Getting Review Data</h3>\n",
    "<p>First we will copy the code from the previous section that sets up all the different varaible names, and added in four new ones: <code>busID</code>, <code>review1</code>, <code>review3</code>, <code>review3.</code> <b>Note the updated name for the variable that holds the payload.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_review = [['Name','Bus_ID','Rating','Url','Price','Lat','Long','Category','Review_1','Review_2','Review_3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to copy the same basic logic as our last iteration of the code but this time we will include a different call to the Yelp API to include the review data. First to be able to ask for review data, we need to get the individual <code>business ID</code> value. This is in the business variable (a dictionary type) with the key ‘id’ – go figure… The line of code to get the business ID is added after the setup of the other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for business in payload['businesses']:\n",
    "    lat = str(business['coordinates']['latitude'])\n",
    "    long = str(business['coordinates']['longitude'])\n",
    "    name = str(business['name'])\n",
    "    url = str(business['url'])\n",
    "    price = business['price'] if 'price' in business else \"null\"\n",
    "    rating = str(business['rating'])\n",
    "    category = str(business['categories'][0]['title'])\n",
    "    \n",
    "    \n",
    "    busID = business['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now we are ready to add in how we are going to query the Yelp API. We create a new request using the requests library before, but we want to use a different endpoint. The endpoint looks like this:<br>\n",
    "\n",
    "<code>https://api.yelp.com/v3/businesses/{id}/reviews</code><br>\n",
    "\n",
    "What we need to do is put the <code>busID</code> variable in the place of <code>{id}</code>.<br>\n",
    "\n",
    "Remember back when I showed you how to add data to strings using the <code>+ operator</code>? Same thing here! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.yelp.com/v3/businesses/'+busID+'/reviews',params={},headers=headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that the <code>params</code> variable is empty. Even though there are no parameters to include from Yelp’s side (see link at top of section), the function <code>requests.get()</code> requires that we set the value for <code>params</code>, so instead we give it an empty variable in the format it is expecting (a Python dictionary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there is a nifty, and lazy bit of code to handle the reviews. It turns out that if you ask for reviews, the Yelp API will send you 0 to 3 reviews based on availability. So, we need to handle for all these cases. The simple way to do it is just to initially set each to <code>null.</code><br>\n",
    "Then we can check how many reviews there are by looking at the length of the array of the review object. Just like when we used the <code>str() command</code>, there is a special command for arrays. We can use <code>len().</code> Add in the following code to find out the length of the array of reviews: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(r[\"reviews\"]) \n",
    "review1,review2,review3=\"null\",\"null\",\"null\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets the variable <code>n</code> to the number of objects in the array. It will be a value from <code>0-3.</code><br>\n",
    "\n",
    "Now that we have default values for the reviews and know the number of reviews, we can overwrite the <code>“null”</code> values when there is data. But, we don’t want to if there is no data. That will result with an array index problem if there is no data! An array index is the position in an array that a value is stored in, starting from <code>0</code>. for example if we have and array of 3 reviews denoted <code>array[index]</code>, the indexes of the array would be <code>array[0]</code> <code>array[1]</code>, and <code>array[2]</code>. If we try to ask for <code>array[3]</code>, and there is no value in <code>array[3]</code>, then the program will crash and burn (throw an exception).<br>\n",
    "To handle the case that we have 1-3 reviews we can use a cheeky little inline if statement. An <code>inline if</code> statement is one that we can evaluate in a single line of code. Usually, you don’t want to do this if the code is complex, but since ours is a pretty simple conditional <code>(if l > value is true)</code> then it’s not a big issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n >0: review1 = r['reviews'][0]['text']\n",
    "if n >1: review2 = r['reviews'][1]['text'] \n",
    "if n >2: review3 = r['reviews'][2]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in these three lines of code, we are overwriting the null values if there is data to write. Otherwise, leave the null value alone. \n",
    "\n",
    "Finally, we just need to update the headings of our payload and the append statement so that it incorporates the new review data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [name,busID,rating,url,price,lat,lon,category,review1,review2,review3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFFF00\"><b>Note: To make things easier I have combined all the cells in this section below. </b>Run the cell below and it will work through the review request code and print the details for each restaurant.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for business in payload['businesses']:\n",
    "    lat = str(business['coordinates']['latitude'])\n",
    "    long = str(business['coordinates']['longitude'])\n",
    "    name = str(business['name'])\n",
    "    url = str(business['url'])\n",
    "    price = business['price'] if 'price' in business else \"null\"\n",
    "    rating = str(business['rating'])\n",
    "    category = str(business['categories'][0]['title'])\n",
    "    \n",
    "    \n",
    "    busID = business['id']\n",
    "    \n",
    "    \n",
    "    r = requests.get('https://api.yelp.com/v3/businesses/'+busID+'/reviews',params={},headers=headers).json()\n",
    "    \n",
    "    \n",
    "    n = len(r[\"reviews\"])\n",
    "    review1,review2,review3=\"null\",\"null\",\"null\"\n",
    "    if n >0: review1 = r['reviews'][0]['text']\n",
    "    if n >1: review2 = r['reviews'][1]['text'] \n",
    "    if n >2: review3 = r['reviews'][2]['text']\n",
    "    \n",
    "    \n",
    "    \n",
    "    l = [name,busID,rating,url,price,lat,long,category,review1,review2,review3]\n",
    "    \n",
    "    print(l)\n",
    "    \n",
    "    payload_review.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! From here we can leave the CSV file writing code alone. <b>Make sure you go through and add in good comments to explain everything that you are doing</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviews.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerows(payload_review)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Connecting to PostGIS</h3>\n",
    "<p>OK, great job so far. But, storing spatial data in CSV is very 1999, and it doesn’t help us when we get to the next task, machine learning. In order to make use of this data we’re going to store the data in PostGIS.<br>\n",
    "First we need to connect to our database.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = \"YOUR DB NAME\"\n",
    "user = \"postgres\"\n",
    "host= \"localhost\"\n",
    "port= \"5432\"\n",
    "password= \"YOUR PASSWORD\"\n",
    "\n",
    "connString = \"dbname=\\'\"+dbname+\"\\' user=\\'\"+user+\"\\' host=\\'\"+host+\"\\' port=\\'\"+port+\"\\' password=\\'\"+password+\"\\'\"\n",
    "\n",
    "conn = psycopg2.connect(connString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to know the SQL that we are going to evaluate. There are two kinds of operations that we can do with Python and PostGIS. \n",
    "<ul><li>We can evaluate SQL commands, like create a table</li>\n",
    "    <li>We can iterate of the rows of a table</li></ul>\n",
    "Either option requires us to create an object called a <code>cursor.</code> The cursor is what allows us to execute command and iterate over data.<br>\n",
    "For right now we just need to know how to complete an SQL command. First though we are going to make a variable called SQL that will hold  the SQL command we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cursor\n",
    "conn.close() #close any open connections (in case bad data)\n",
    "conn = psycopg2.connect(connString) #reopen the connection\n",
    "\n",
    "curr = conn.cursor()\n",
    "\n",
    "#formatting\n",
    "sql=\"CREATE TABLE public.yelp_data \\\n",
    "( \\\n",
    "    geom geometry, \\\n",
    "    oid serial NOT NULL, \\\n",
    "    busid character varying, \\\n",
    "    name character varying, \\\n",
    "    url character varying, \\\n",
    "    price character varying, \\\n",
    "    rating character varying, \\\n",
    "    category character varying, \\\n",
    "    review1 character varying, \\\n",
    "    review2 character varying, \\\n",
    "    review3 character varying, \\\n",
    "    PRIMARY KEY (oid) \\\n",
    ")\"\n",
    "\n",
    "\n",
    "curr.execute(sql)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the above code that we don’t end the string using the <code>\"\"</code> characters until the end. We can do that because we tell Python that we are going to keep going, by using the <code>\"\\\\\"</code> command at the end of the line. Now that we have some SQL the cursor  executes the command and then commits the change to the database.<br><br>\n",
    "With that, our table is made (have a look at pgAdmin if you want to see it!) but it needs an <code>index</code> to keep it running smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cursor\n",
    "conn.close()\n",
    "conn = psycopg2.connect(connString)\n",
    "\n",
    "curr = conn.cursor()\n",
    "\n",
    "sql=\"CREATE INDEX geom_index ON public.yelp_data USING gist (geom) TABLESPACE pg_default; \"\n",
    "\n",
    "curr.execute(sql)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is that we need to get our Yelp data into PostGIS. The good news is that the data is beautifully formatted (if I do say so myself) as the variable <code>payload_review.</code> All we need to do now is loop through the items in <code>payload_review</code> and evaluate each as SQL. The loop part of the code should seem pretty familiar, but in the loop statement I added a <code>[1:].</code> This is a short form for saying, just use the array elements starting at index 1 forward, since the first item in the array are the column names anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cursor\n",
    "conn.close()\n",
    "conn = psycopg2.connect(connString)\n",
    "\n",
    "curr = conn.cursor()\n",
    "\n",
    "for b in payload_review[1:]:\n",
    "    sql=\"INSERT INTO yelp_data(geom,busid,name,url,price,rating,category,review1,review2,review3) \\\n",
    "    VALUES(ST_GeomFromText(\\'POINT(\"+str(b[6])+\" \"+str(b[5])+\")\\',4326),\\' \"+b[1]+\" \\' ,$$\"+b[0]+\" \\\n",
    "    $$,\\'\"+b[3]+\"\\',\\'\"+b[4]+\"\\', \\'\"+b[2]+\"\\',\\'\"+b[7]+\"\\',$$\"+b[8]+\"$$,$$\"+b[9]+\"$$,$$\"+b[10]+\"$$)\"\n",
    "    \n",
    "    curr.execute(sql)\n",
    "    \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code you’ll notice a couple new things, but basically, we are doing a standard insert command in SQL. But, for the geometry data I’m using a <code>ST_GeomFromText</code> command, which is a PostGIS operator (think lab 2), and I’m using the <code>$$data$$</code> format in a couple fields of text. The <code>\\$\\$</code> operator allows us to use text that has elements that would otherwise cause errors such as apostrophes and punctuation marks for example <code>I’ve gone to heaven!</code>\n",
    "Whew, that’s it! You should now be able to see your data in PostGIS, or even QGIS if you use the DB manager.\n",
    "\n",
    "## Part 4: Using Topic Modelling on Review Data\n",
    "In this section of the lab, we are going to use a method from natural language processing called Latent Dirichlet Allocation (LDA). LDA helps us pull out topics in the data so that we don’t have to read all the text to see what is going on. I’ve used this method with Twitter data before, but let’s take a look at how well it can do with reviews. We will be using the <code>gensim</code> library we imported in the first cell. The LDA model can be a bit confusing, but [here is a good article](https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158) that explains it in simple terms\n",
    "    \n",
    "<p>First we will import the data we are going to use for our topic model from PostGIS in a new cell:</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting GENSIM code\")\n",
    "documents=[]\n",
    "conn = psycopg2.connect(connString)\n",
    "curr = conn.cursor()\n",
    "curr.execute(\"SELECT review1,review2,review3 FROM yelp_data\")\n",
    "review_data = []\n",
    "for i in curr:\n",
    "    if i[0] != 'null': review_data.append(i[0]) #don't add null\n",
    "    if i[1] != 'null': review_data.append(i[1]) #don't add null\n",
    "    if i[2] != 'null': review_data.append(i[2]) #don't add null\n",
    "\n",
    "logging.info(\"%s reviews recieved\" , len(review_data))\n",
    "conn.close()\n",
    "\n",
    "for review in review_data:\n",
    "    documents.append(' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(gt)\",\" \",review).split()).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did above is pretty understandable. We simply grabbed our review data from PostGIS, and formatted it into an array of reviews, one after another, regardless of where it came from. While this kills our nicely formatted data, that’s OK because we are going to create a model that doesn’t care about format anyways.<br><br>\n",
    "This next cell is a lot of pretty dense code. I won’t try to explain it all here, but have a look at the tutorials [here](https://radimrehurek.com/gensim/tutorial.html) if you’re interested. It’s pretty cool stuff! Basically, we are removing words that we don’t care about like prepositions and words that only occur once (this is what the <code>stoplist</code> (long list of words) on line 6 is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"CORPUS SIZE AFTER REGEX: \"+str(len(documents)))\n",
    "\n",
    "stoplist = set(\"a about above after again against all am an and any are aren\\'t as at be because been before being below between both but by can\\'t cannot could couldn\\'t did didn\\'t do does doesn\\'t doing don\\'t down during each few for from further had hadn\\'t has hasn\\'t have haven\\'t having he he'd he\\'ll he\\'s her here here\\'s hers herself him himself his how how\\'s i i\\'d i\\'ll i\\'m i\\'ve if in into is  isn\\'t it it\\'s its itself let\\'s me more most mustn't my myself no nor not of off on once only or other ought our ours ourselves out over own same shan\\'t she she\\'d she\\'ll she\\'s should shouldn\\'t so some something such than that that\\'s the their theirs them themselves then there there\\'s these they they\\'d they\\'ll they're they\\'ve this those through to too under until up very was wasn\\'t we we\\'d we\\'ll we\\'re we\\'ve were weren\\'t what what\\'s when when\\'s where where\\'s which while who who\\'s whom why why\\'s with won\\'t would wouldn\\'t you you\\'d you\\'ll you\\'re you\\'ve your yours yourself yourselves a b c d e f g h i j k l m n o p q r s t u v w x y z don que con en de le sus el re ll rt si go can la ve hi ur dis ain es wanna couldn thx je te ese rn tu ya lo como por pm ca amp como me je oye mi del tho un une da los doin yo nah im lt da se su thru vs una mas uno imma didn ni para tira pa las nos esto dm say know like ima just thought tx way whats say get said dem esta going dont get san qu bien even mf yea good seems knew thing except san yay sabes really yes mis soy vaz em wasn xo got goes need never il ah hey doesn vos keep already telling keeps people much think talk will estar cuando telling shouldno ida llevar much talk feel every someone oh haha miss cause ser tiempo now told come back one al watching thank cant back looks great much mean plase seb dormir ser plzz thanks new literally soon take must time try still end join tbt see las right look anything anymore better tag make makes sure start okay aren give hard pretty let finally start many ever na ng ko stop looking seeing actually things ha probably tonight nice today says ready without done everyone nothing tilltell meet coming others next absolutely hoy bye ma made tug yeah enjoy lil late day side piece find shout dude dudes appearently favourite definitely 0 1 2 3 4 5 6 7 8 9 tell find words want met gea leave please guys guy us sounds otherwise big name amazing missing biyi isn happened besides donde via vamos sleep bed morning put hours finna af phil saying amor est mine iight put joe fuck fucking shit stay stand row wear via hours aqui hay monday tuesday wednesday thursday friday saturday sunday remember close long jerry centro last omg lol lmfao rofl place seen early gotta whole ones stand ok wait lmao year trippin hasta messing lame ugh yet wtf idk act bae away anyone bring damn ig pues alright tf might xd wrong starting little maybe gets sometimes known getting whatever later together left gonna else tf anybody nobodyana starting whatever needs casa happiest bout lefttil eso almost everybody till swear yall around excited best wrong follow far annoying pls gonna favorite babe maybe wants\".split())\n",
    "s = \"\"\n",
    "for w in stoplist:\n",
    "    s+=w+\" \"\n",
    "    stoplist = set(s.split())\n",
    "\n",
    "#tokenize\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\t\t\n",
    "logging.info(\"CORPUS SIZE AFTER STOPLIST: \"+str(len(texts)))\n",
    "\n",
    "\n",
    "#remove words only spoken once\n",
    "all_tokens = sum(texts, [])\n",
    "logging.info(\"beginning tokenization\")\n",
    "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
    "logging.info(\"words tokenized, starting single mentioned word reduction\")\n",
    "texts = [[word for word in text if word not in tokens_once] for text in texts]\n",
    "logging.info(\"words mentioned only once removed\")\n",
    "\n",
    "#get rid of null entries\n",
    "#texts = filter(None,texts)\n",
    "logging.info(\"CORPUS SIZE AFTER EMPTY ROWS REMOVED: \"+str(len(texts)))\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "tfidf = models.TfidfModel(corpus) #step 1. --initialize(train) a model\n",
    "\n",
    "corpus_tfidf = tfidf[corpus] # Apply TFIDF transform to entire corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>These next lines of code actually run the model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(len(corpus_tfidf))\n",
    "logging.info(\"starting LDA model\")\n",
    "\n",
    "model = models.ldamodel.LdaModel(corpus_tfidf, id2word=dictionary, alpha=0.001, num_topics=10, update_every=0, passes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can actually run that model. It will create a lot of text, visually showing you the output of the model as it fits words to topics. The power of the model is that it continues to ‘pass’ over the data increasing the probabilities that the words actually fit in those distributions. [Check this out](https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158) if you're a bit lost on how the LDA model works and how to read the output.<br><br>\n",
    "To actually see the model output there is one final line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(model.show_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that the probabilities are really low. You can try mucking around with the model, mostly with the number of passes to try and get a better output. Try 100 passes or 500 passes.</p><hr>\n",
    "<p>Unfortunately, the results aren’t that great because the corpus are just too small. I have however, got my grubby little hands on the Yelp Academic Dataset. This dataset is honestly pretty big with over 6 million reviews in it. Yes, it is tempting to create a model of the entire corpus, but then again, we probably want to be done with this assignment, so we will work with a small section of the dataset.</p>\n",
    "<p>In the handout files you will find the file <code>rev_subset_50k.json</code> this is a subset of the review’s dataset down to 50,000 reviews. The JSON file is a little disorganized, with each new line of the file being a new JSON object.</p>\n",
    "<p>As this is a text file it is pretty easy to read into Python:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rev_subset_50k.json',encoding='utf8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for line in lines:\n",
    "        d = ast.literal_eval(str(line)[:-1])\n",
    "        documents.append(d['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This block of code reads the data from the JSON file, extracts just the text of the reviews and adds it all to the varaible named <code>documents</code> that we used earlier overwriting the older data. From here you can copy the code from above to do the word tokenization and stoplist creation. I won’t copy the code here as it is already in your Python notebook. Take a look at the screenshot in the main instructions file for an example of the working code.</p>\n",
    "<p>After this, just add the code that runs the model in the next cell. Keep in mind that because this is a big dataset, it will take time for the code to run. <b>I would also make sure that you reduce the number of passes over the data.</b> Start with a small number like 10 to see how long that takes, and you can increase it from there.</p>\n",
    "<p>The model output is in the format of an array. <b>Use your skills as a programmer to output the final topic model as a CSV file, and open this in Excel.</b></p>\n",
    "<p><b>Head back to the main instructions document</b> for instructions on how to complete the rest of the assignment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
